spring:
  application:
    name: chatbot

  ai:
    mcp:
      client:
        sse:
          connections:
            server:
              url: http://localhost:8083
          #stdio:
          #servers-configuration: classpath:/mcp-servers-config.json

    ollama:
      base-url: http://localhost:11434
      chat:
        options:
          model: llama3.1
      embedding:
        options:
          model: mxbai-embed-large

    vectorstore:
      chroma:
        client:
          host: http://localhost:8080
        initialize-schema: true

  threads:
    virtual:
      enabled: true

  docker:
    compose:
      enabled: true
      file: ./compose.yaml
      stop:
        command: down

server:
  port: 8084

# OpenAI
# spring:
#   ai:
#     openai:
#       api-key: ${OPENAI_API_KEY}
#       chat:
#         options:
#           model: gpt-4o-mini
